---
title: "Autonomous Driving using End-to-End Reinforcement Learning"
excerpt: "Autonomous driving trained using end-to-end RL."
header:
  teaser: /assets/images/AirSim_RL_teaser.png
---


This project explores an approach to autonomous driving using Deep Reinforcement Learning (DRL). Instead of relying on pre-programmed rules, our model learns to drive by interacting with a simulated environment, much like a human or animal learns from experience.

The core of the project is a Dueling Double Deep Q-Learning algorithm, which extends the popular Q-learning. The system is designed as an end-to-end model, meaning it takes raw camera images as input and directly outputs control commands for the car (like steering and throttle).

No specific driving rules or guidelines are given to the controller but it should rather learn based on feedback given when the vehicle leaves the road or collides into another vehicle or obstacle.

Experiments were conducted in two different driving simulators, Airsim and Carla, to test the model's capabilities in various scenarios. The results were highly promising:

- In the Airsim environment, the virtual vehicle successfully learned to navigate a long road, avoid parked cars, and even execute turns at the end of the road.
- In the Carla simulator, the car was able to drive to a specific destination, demonstrating its ability to handle goal-oriented tasks.

This project highlights the potential of DRL to create intelligent, adaptable, and safe autonomous systems. It's an exciting step toward a future where vehicles can learn and operate autonomously in the real world.

### Video: first epochs of training

<video width="100%" controls>
  <source src="{{ '/assets/videos/before_train.mp4' | relative_url }}" type="video/mp4">
  Your browser does not support the video tag.
</video>

### Video: after training

<video width="100%" controls>
  <source src="{{ '/assets/videos/AirSim_RL.mp4' | relative_url }}" type="video/mp4">
  Your browser does not support the video tag.
</video>
